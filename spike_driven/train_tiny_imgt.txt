## tiny imagenet 224 T=4
CUDA_VISIBLE_DEVICES=0 torchrun --nproc_per_node=1 /zhengzeqi/top_down/spikedriven/github_version/train.py \
-c /zhengzeqi/top_down/spikedriven/github_version/conf/tiny_imagenet/6_512_300E_t4.yml \
--model sdt \
--output /zhengzeqi/top_down/spikedriven/github_version/weights \
--batch-size 512 \
--experiment tiny_imagenet_T_4_baseline



## tiny imagenet 224 T=4 baseline
CUDA_VISIBLE_DEVICES=0 torchrun --nproc_per_node=1 /zhengzeqi/top_down/spikedriven/github_version/train.py \
-c /zhengzeqi/top_down/spikedriven/github_version/conf/imagenet/6_512_300E_t4.yml \
--model sdt \
--output /zhengzeqi/top_down/spikedriven/github_version/weights \
--experiment imagenet_T_4_baseline




## spike representation baseline
CUDA_VISIBLE_DEVICES=0 torchrun --nproc_per_node=1 --master_port=29502 /zhengzeqi/top_down/spikedriven/github_version/train.py \
-c /zhengzeqi/top_down/spikedriven/github_version/conf/tiny_imagenet/6_512_300E_t4_from_cifar10.yml \
--model sdt \
--output /zhengzeqi/top_down/spikedriven/github_version/weights/tmp \
--time-steps 6 \
--batch-size 128 \
--val-batch-size 128 \
--resume /zhengzeqi/top_down/spikedriven/github_version/weights/tiny_imagenet_T_6_baseline/model_best.pth.tar \
--spike_re_save_pth /zhengzeqi/top_down/spikedriven/github_version/representation \
--spike_re_eval \
--dataset_name tiny_imagenet_200_baseline


## spike representation 3d_pe_arch_1

CUDA_VISIBLE_DEVICES=0 torchrun --nproc_per_node=1 --master_port=29502 /zhengzeqi/top_down/spikedriven/github_version/train.py \
-c /zhengzeqi/top_down/spikedriven/github_version/conf/tiny_imagenet/6_512_300E_t4_from_cifar10.yml \
--model sdt \
--output /zhengzeqi/top_down/spikedriven/github_version/weights/tmp \
--time-steps 6 \
--batch-size 128 \
--val-batch-size 128 \
--resume /zhengzeqi/top_down/spikedriven/github_version/weights/tiny_imagenet_T_6_3d_pe_arch_1/model_best.pth.tar \
--spike_re_save_pth /zhengzeqi/top_down/spikedriven/github_version/representation \
--spike_re_eval \
--recurrent_coding \
--pe_type 3d_pe_arch_1 \
--dataset_name tiny_imagenet_200




## tiny imagnet 224 T=4, 3d_pe_arch_1, lif_recurrent_state
python -m torch.distributed.launch --nproc_per_node=1 /zhengzeqi/top_down/spikedriven/github_version/train.py \
-c /zhengzeqi/top_down/spikedriven/github_version/conf/tiny_imagenet/6_512_300E_t4_from_cifar10.yml \
--model sdt \
--output /zhengzeqi/top_down/spikedriven/github_version/weights \
--time-steps 4 \
--batch-size 128 \
--val-batch-size 128 \
--recurrent_coding \
--pe_type 3d_pe_arch_1 \
--lif_recurrent_state 1111111111111111111111111111111111111111111111 \
--experiment tiny_imagenet_T_4_3d_pe_arch_1_lif_recurrent_all


